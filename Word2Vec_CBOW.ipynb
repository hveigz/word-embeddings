{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from: <br>\n",
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#an-example-n-gram-language-modeling <br>\n",
    "https://gist.github.com/GavinXing/9954ea846072e115bb07d9758892382c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 77777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our toy dataset with a few sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'a', 'computational', 'process.', 'Computational', 'processes', 'are', 'abstract', 'beings', 'that', 'inhabit', 'computers.', 'As', 'they', 'evolve,', 'processes', 'manipulate', 'other', 'abstract', 'things', 'called', 'data.', 'The', 'evolution', 'of', 'a', 'process', 'is', 'directed', 'by', 'a', 'pattern', 'of', 'rules', 'called', 'a', 'program.', 'People', 'create', 'programs', 'to', 'direct', 'processes.', 'In', 'effect,', 'we', 'conjure', 'the', 'spirits', 'of', 'the', 'computer', 'with', 'our', 'spells.']\n"
     ]
    }
   ],
   "source": [
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize the dataset and map each word to a unique index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i: word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 words in the vocabulary\n",
      "\n",
      "{'computational': 0, 'Computational': 1, 'the': 2, 'create': 3, 'we': 4, 'The': 5, 'processes': 6, 'abstract': 7, 'pattern': 8, 'process': 9, 'by': 10, 'to': 11, 'As': 12, 'rules': 13, 'is': 14, 'with': 15, 'things': 16, 'are': 17, 'evolve,': 18, 'spirits': 19, 'they': 20, 'study': 21, 'about': 22, 'process.': 23, 'beings': 24, 'idea': 25, 'computer': 26, 'conjure': 27, 'programs': 28, 'We': 29, 'In': 30, 'other': 31, 'directed': 32, 'a': 33, 'program.': 34, 'inhabit': 35, 'manipulate': 36, 'effect,': 37, 'People': 38, 'evolution': 39, 'of': 40, 'called': 41, 'that': 42, 'data.': 43, 'processes.': 44, 'direct': 45, 'spells.': 46, 'computers.': 47, 'our': 48}\n"
     ]
    }
   ],
   "source": [
    "print(str(vocab_size) + \" words in the vocabulary\")\n",
    "print()\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the context - target observations to input into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to transform input observations into vectors with corresponding vocabulary indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.LongTensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'are', 'to', 'study']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First observation\n",
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 29,  17,  11,  21])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_context_vector(data[0][0], word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1103f78b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, context_size, embedding_size, vocab_size=None):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.linear1 = nn.Linear(embedding_size, vocab_size)\n",
    "\n",
    "    def embed(self, inputs):\n",
    "        embedded = self.embeddings(inputs)\n",
    "        return embedded\n",
    "                \n",
    "    def forward(self, inputs):        \n",
    "        embeds_sum = self.embed(inputs).sum(dim=0)\n",
    "        out = self.linear1(embeds_sum)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 500\n",
    "\n",
    "vocab_size=vocab_size\n",
    "context_size=2\n",
    "embedding_size=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "model = CBOW(context_size=context_size, embedding_size=embedding_size, vocab_size=vocab_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 - Loss: 260.169891\n",
      "Train Epoch: 50 - Loss: 21.289560\n",
      "Train Epoch: 100 - Loss: 6.683471\n",
      "Train Epoch: 150 - Loss: 3.555195\n",
      "Train Epoch: 200 - Loss: 2.336178\n",
      "Train Epoch: 250 - Loss: 1.710035\n",
      "Train Epoch: 300 - Loss: 1.335281\n",
      "Train Epoch: 350 - Loss: 1.088280\n",
      "Train Epoch: 400 - Loss: 0.914324\n",
      "Train Epoch: 450 - Loss: 0.785756\n",
      "Train Epoch: 500 - Loss: 0.687183\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs+1):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        context_var = make_context_vector(context, word_to_ix)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        probs = model(context_var).view(1,-1)\n",
    "        loss = loss_func(probs, torch.LongTensor([word_to_ix[target]]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print('Train Epoch: {} - Loss: {:.6f}'.format(\n",
    "                    epoch, total_loss.item() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(data, i):\n",
    "    \n",
    "    v = make_context_vector(data[i][0], word_to_ix)\n",
    "    #print(v)\n",
    "    \n",
    "    output=model(v)    \n",
    "    #print(output)\n",
    "    \n",
    "    _, predicted = torch.max(output, 0)\n",
    "    \n",
    "    print(\"Context: \"+str(data[i][0]))\n",
    "    print(\"Output for the word with highest likelihood: \"+str(_.item()))\n",
    "    print(\"Predicted word: \"+str(ix_to_word[predicted.item()]))\n",
    "    print(\"True word: \"+str(data[i][1]))\n",
    "    print()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['We', 'are', 'to', 'study']\n",
      "Output for the word with highest likelihood: 12.355534553527832\n",
      "Predicted word: about\n",
      "True word: about\n",
      "\n",
      "Context: ['are', 'about', 'study', 'the']\n",
      "Output for the word with highest likelihood: 13.095701217651367\n",
      "Predicted word: to\n",
      "True word: to\n",
      "\n",
      "Context: ['about', 'to', 'the', 'idea']\n",
      "Output for the word with highest likelihood: 12.992199897766113\n",
      "Predicted word: study\n",
      "True word: study\n",
      "\n",
      "Context: ['to', 'study', 'idea', 'of']\n",
      "Output for the word with highest likelihood: 13.817288398742676\n",
      "Predicted word: the\n",
      "True word: the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    get_prediction(data, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check embedding vectors for the first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'are', 'to', 'study']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>We</th>\n",
       "      <td>0.126473</td>\n",
       "      <td>-0.678771</td>\n",
       "      <td>0.486892</td>\n",
       "      <td>-1.115773</td>\n",
       "      <td>1.589510</td>\n",
       "      <td>-0.743425</td>\n",
       "      <td>1.538858</td>\n",
       "      <td>1.566961</td>\n",
       "      <td>0.499367</td>\n",
       "      <td>-0.511873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>-1.034676</td>\n",
       "      <td>-0.252601</td>\n",
       "      <td>-1.139089</td>\n",
       "      <td>-0.681244</td>\n",
       "      <td>0.096220</td>\n",
       "      <td>-0.094143</td>\n",
       "      <td>1.211157</td>\n",
       "      <td>2.939287</td>\n",
       "      <td>-0.892874</td>\n",
       "      <td>0.790775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-2.353026</td>\n",
       "      <td>0.742168</td>\n",
       "      <td>-0.135938</td>\n",
       "      <td>1.189165</td>\n",
       "      <td>0.391911</td>\n",
       "      <td>0.499691</td>\n",
       "      <td>1.386475</td>\n",
       "      <td>-1.273110</td>\n",
       "      <td>-0.858032</td>\n",
       "      <td>0.206108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <td>0.415411</td>\n",
       "      <td>-1.001889</td>\n",
       "      <td>0.987945</td>\n",
       "      <td>0.937073</td>\n",
       "      <td>0.712470</td>\n",
       "      <td>0.521906</td>\n",
       "      <td>-1.272960</td>\n",
       "      <td>0.491454</td>\n",
       "      <td>-0.371379</td>\n",
       "      <td>-1.117039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "We     0.126473 -0.678771  0.486892 -1.115773  1.589510 -0.743425  1.538858   \n",
       "are   -1.034676 -0.252601 -1.139089 -0.681244  0.096220 -0.094143  1.211157   \n",
       "to    -2.353026  0.742168 -0.135938  1.189165  0.391911  0.499691  1.386475   \n",
       "study  0.415411 -1.001889  0.987945  0.937073  0.712470  0.521906 -1.272960   \n",
       "\n",
       "              7         8         9  \n",
       "We     1.566961  0.499367 -0.511873  \n",
       "are    2.939287 -0.892874  0.790775  \n",
       "to    -1.273110 -0.858032  0.206108  \n",
       "study  0.491454 -0.371379 -1.117039  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = make_context_vector(data[0][0], word_to_ix)\n",
    "embedded_vector = model.embed(vector).data.numpy()\n",
    "pd.DataFrame(embedded_vector, index=data[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
